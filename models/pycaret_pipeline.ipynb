{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret Pipeline for PD-L1 Prediction\n",
    "\n",
    "This notebook demonstrates the PyCaret-based machine learning pipeline for predicting PD-L1 expression from radiomics features.\n",
    "\n",
    "## Workflow:\n",
    "1. Load and prepare data\n",
    "2. Feature selection using stability selection\n",
    "3. Model training and comparison\n",
    "4. Model evaluation on hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from tableone import TableOne\n",
    "import pandas as pd\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "⚠️ **USER ACTION REQUIRED**: Load your radiomics features and labels here.\n",
    "\n",
    "Expected data format:\n",
    "- `feature_train`: DataFrame with radiomics features (rows=patients, columns=features)\n",
    "- `feature_test`: DataFrame with test set features\n",
    "- Target column: `encoded_PDL1` with values {0, 1, 2} for PD-L1 categories\n",
    "\n",
    "Example:\n",
    "```python\n",
    "feature_train = pd.read_csv('./data/train_features.csv', index_col=0)\n",
    "feature_test = pd.read_csv('./data/test_features.csv', index_col=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data here\n",
    "# feature_train = pd.read_csv('./data/train_features.csv', index_col=0)\n",
    "# feature_test = pd.read_csv('./data/test_features.csv', index_col=0)\n",
    "\n",
    "# Prepare data\n",
    "data = feature_train\n",
    "data['encoded_PDL1'] = data['encoded_PDL1'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection with Stability Selection\n",
    "\n",
    "Use stability selection with Logistic Regression to identify robust features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --------- Functions ---------\n",
    "\n",
    "def compute_validation_scores_and_coefficients(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    n_cs=15, random_state=3457\n",
    "):\n",
    "    \"\"\"\n",
    "    Train on X_train, validate on X_val to select optimal C.\n",
    "    Also computes coefficient paths for visualization.\n",
    "    Parallelizes the C-loop across cores.\n",
    "    \"\"\"\n",
    "    C_values     = np.logspace(-3, 3, n_cs)\n",
    "    log_C_values = np.log10(C_values)\n",
    "    feature_names = X_train.columns.tolist()\n",
    "\n",
    "    def eval_one_C(idx, C):\n",
    "        pipe = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                C=C, penalty='l1', solver='saga',\n",
    "                multi_class='multinomial', max_iter=10_000,\n",
    "                random_state=random_state, n_jobs=1\n",
    "            )\n",
    "        )\n",
    "        pipe.fit(X_train, y_train)\n",
    "        val   = log_loss(y_val, pipe.predict_proba(X_val))\n",
    "        coef  = pipe.named_steps['logisticregression'].coef_.copy()\n",
    "        return val, coef\n",
    "\n",
    "    results = Parallel(n_jobs=-1, verbose=5)(\n",
    "        delayed(eval_one_C)(i, C) for i, C in enumerate(C_values)\n",
    "    )\n",
    "\n",
    "    val_scores, coef_paths = zip(*results)\n",
    "    val_scores = np.array(val_scores)               # (n_cs,)\n",
    "    coef_paths = np.stack(coef_paths, axis=0)       # (n_cs, n_classes, n_features)\n",
    "\n",
    "    best_idx     = val_scores.argmin()\n",
    "    optimal_C    = C_values[best_idx]\n",
    "    optimal_loss = val_scores[best_idx]\n",
    "\n",
    "    return {\n",
    "        'optimal_C':      optimal_C,\n",
    "        'optimal_loss':   optimal_loss,\n",
    "        'C_values':       C_values,\n",
    "        'log_C_values':   log_C_values,\n",
    "        'val_scores':     val_scores,\n",
    "        'coef_paths':     coef_paths,\n",
    "        'feature_names':  feature_names\n",
    "    }\n",
    "\n",
    "def fit_final_model(X, y, C, random_state=3457):\n",
    "    \"\"\"\n",
    "    Fit on X,y with given C, return pipeline, selected features, and coef matrix.\n",
    "    \"\"\"\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            C=C, penalty='l1', solver='saga',\n",
    "            multi_class='multinomial', max_iter=10_000,\n",
    "            random_state=random_state, n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "    pipe.fit(X, y)\n",
    "    coefs = pipe.named_steps['logisticregression'].coef_          # (n_classes, n_features)\n",
    "    mask  = np.any(coefs != 0, axis=0)\n",
    "    selected = X.columns[mask].tolist()\n",
    "    return pipe, selected, coefs\n",
    "\n",
    "\n",
    "X_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "n_inner  = 2\n",
    "n_cs     = 20\n",
    "\n",
    "# Directory for saving plots\n",
    "NESTED_OUTPUT_DIR = \"\"\n",
    "os.makedirs(NESTED_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --------- Outer folds in parallel ---------\n",
    "outer_splits = list(enumerate(outer_cv.split(X_full, y_full), 1))\n",
    "\n",
    "def process_outer(fold_tuple):\n",
    "    fold_idx, (tr_idx, te_idx) = fold_tuple\n",
    "    X_tr, X_te = X_full.iloc[tr_idx], X_full.iloc[te_idx]\n",
    "    y_tr, y_te = y_full.iloc[tr_idx], y_full.iloc[te_idx]\n",
    "\n",
    "    # inner split for hyperparameter tuning\n",
    "    inner = StratifiedKFold(n_splits=n_inner, shuffle=True, random_state=fold_idx+123)\n",
    "    itr, ivl = next(inner.split(X_tr, y_tr))\n",
    "    X_ti, X_vi = X_tr.iloc[itr], X_tr.iloc[ivl]\n",
    "    y_ti, y_vi = y_tr.iloc[itr], y_tr.iloc[ivl]\n",
    "\n",
    "    # tune C\n",
    "    res = compute_validation_scores_and_coefficients(X_ti, y_ti, X_vi, y_vi, n_cs=n_cs)\n",
    "\n",
    "    # fit on outer-train with its best C, extract features\n",
    "    pipe, sel, _ = fit_final_model(X_tr, y_tr, res['optimal_C'])\n",
    "\n",
    "    return {\n",
    "        'val_scores':    res['val_scores'],\n",
    "        'coef_paths':    res['coef_paths'],\n",
    "        'feature_names': res['feature_names'],\n",
    "        'C_values':      res['C_values'],       # <— now included\n",
    "        'log_C_values':  res['log_C_values'],   # <— now included\n",
    "        'optimal_C':     res['optimal_C'],\n",
    "        'selected':      sel\n",
    "    }\n",
    "\n",
    "# run all outer folds in parallel\n",
    "fold_results = Parallel(n_jobs=-1, verbose=5)(\n",
    "    delayed(process_outer)(fs) for fs in outer_splits\n",
    ")\n",
    "\n",
    "# collect\n",
    "all_vs             = [fr['val_scores']    for fr in fold_results]\n",
    "all_coefs          = [fr['coef_paths']    for fr in fold_results]\n",
    "selected_per_fold  = [fr['selected']      for fr in fold_results]\n",
    "C_grid             = fold_results[0]['C_values']\n",
    "log_C_grid         = fold_results[0]['log_C_values']\n",
    "feature_names      = fold_results[0]['feature_names']\n",
    "\n",
    "# --------- Consensus Hyperparameter ---------\n",
    "vs_arr      = np.stack(all_vs)            # (n_folds, n_cs)\n",
    "mean_vs     = vs_arr.mean(axis=0)\n",
    "std_vs      = vs_arr.std(axis=0)\n",
    "best_idx    = mean_vs.argmin()\n",
    "consensus_C = C_grid[best_idx]\n",
    "print(f\"\\n→ Consensus C (mean inner‑CV): {consensus_C:.4g}\")\n",
    "\n",
    "# --------- Merged Validation Curve ---------\n",
    "fig_val = go.Figure()\n",
    "fig_val.add_trace(go.Scatter(\n",
    "    x=np.concatenate([log_C_grid, log_C_grid[::-1]]),\n",
    "    y=np.concatenate([mean_vs - std_vs, (mean_vs + std_vs)[::-1]]),\n",
    "    fill='toself', fillcolor='rgba(128,128,128,0.2)',\n",
    "    line=dict(color='rgba(0,0,0,0)'), showlegend=False\n",
    "))\n",
    "fig_val.add_trace(go.Scatter(\n",
    "    x=log_C_grid, y=mean_vs, mode='lines', name='Mean Log‑Loss'\n",
    "))\n",
    "fig_val.update_layout(\n",
    "    title=\"Nested CV Mean Validation Curve\",\n",
    "    xaxis_title=\"log10(C)\", yaxis_title=\"Log‑Loss\"\n",
    ")\n",
    "fig_val.write_html(os.path.join(NESTED_OUTPUT_DIR, \"merged_validation_curve.html\"))\n",
    "fig_val.write_image(os.path.join(NESTED_OUTPUT_DIR, \"merged_validation_curve.svg\"))\n",
    "fig_val.show()\n",
    "\n",
    "# --------- Merged Coefficient Paths ---------\n",
    "cp_arr  = np.stack(all_coefs)            # shape (n_folds, n_cs, n_classes, n_features)\n",
    "mean_cp = cp_arr.mean(axis=0)            # (n_cs, n_classes, n_features)\n",
    "fnames  = feature_names\n",
    "n_classes = mean_cp.shape[1]\n",
    "\n",
    "# pick top‑5 features by max absolute mean coeff across all classes\n",
    "maxf   = np.max(np.abs(mean_cp), axis=(0,1))\n",
    "topk   = np.argsort(maxf)[-3:]\n",
    "\n",
    "fig_all = go.Figure()\n",
    "for i in topk:\n",
    "    for cls in range(n_classes):\n",
    "        fig_all.add_trace(go.Scatter(\n",
    "            x=log_C_grid,\n",
    "            y=mean_cp[:, cls, i],\n",
    "            mode='lines',\n",
    "            name=f\"{fnames[i]} (class {cls})\"\n",
    "        ))\n",
    "\n",
    "fig_all.update_layout(\n",
    "    title=\"Nested CV Mean Coefficient Paths (all classes)\",\n",
    "    xaxis_title=\"log10(C)\",\n",
    "    yaxis_title=\"Coefficient\"\n",
    ")\n",
    "fig_all.write_html(os.path.join(NESTED_OUTPUT_DIR, \"merged_coefficient_paths_all_classes.html\"))\n",
    "fig_all.write_image(os.path.join(NESTED_OUTPUT_DIR, \"merged_coefficient_paths_all_classes.svg\"))\n",
    "fig_all.show()\n",
    "\n",
    "# --------- Final Fit on All Train+Val ---------\n",
    "final_pipe, final_features, _ = fit_final_model(X_full, y_full, consensus_C)\n",
    "print(f\"\\nFinal selected features ({len(final_features)}):\")\n",
    "print(final_features)\n",
    "\n",
    "# --------- Stable Features Across Folds ---------\n",
    "counts      = Counter(f for fold_sel in selected_per_fold for f in fold_sel)\n",
    "stable_feats = [f for f, c in counts.items() if c >= 2]  # appear in ≥2 of 3 folds\n",
    "print(\"\\nFeatures selected in ≥2 folds:\")\n",
    "print(stable_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit on stable_feats alone\n",
    "X_stable = X_full[stable_feats]\n",
    "stable_pipe, _, _ = fit_final_model(X_stable, y_full, consensus_C)\n",
    "\n",
    "# extract and tabulate\n",
    "lr2 = stable_pipe.named_steps['logisticregression']\n",
    "coefs2   = lr2.coef_                     # (n_classes, len(stable_feats))\n",
    "classes2 = lr2.classes_\n",
    "\n",
    "stable_coef_df = pd.DataFrame(\n",
    "    data=coefs2.T,\n",
    "    index=stable_feats,\n",
    "    columns=[f\"class_{c}\" for c in classes2]\n",
    ")\n",
    "\n",
    "stable_coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_feats.remove('pre_logarithm_firstorder_Mean')\n",
    "stable_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = stable_feats\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clinical Data Integration\n",
    "\n",
    "⚠️ **USER ACTION REQUIRED**: Load clinical/immunological data here.\n",
    "\n",
    "Expected columns: Clinical factors relevant to your study\n",
    "\n",
    "Example:\n",
    "```python\n",
    "clinical_data = pd.read_excel('./data/clinical_factors.xlsx', index_col=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyCaret Setup and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data for Modeling: ' + str(train_data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holdout Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdl1_clf = setup(data=train_data,\n",
    "                 test_data=test_data,\n",
    "            target='PD-L1',\n",
    "            categorical_features = [''],\n",
    "            ordinal_features= {'TD': [1.0, 2.0, 34]},\n",
    "            remove_outliers = True,\n",
    "            normalize=True, \n",
    "            normalize_method='zscore', \n",
    "            data_split_shuffle=True, \n",
    "            data_split_stratify='PD-L1',\n",
    "            fold = 5,\n",
    "            fold_strategy = 'stratifiedkfold',\n",
    "            fold_shuffle = True, \n",
    "            session_id=3457, \n",
    "            use_gpu=True,\n",
    "            max_encoding_ohe=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique labels:\", train_data['PD-L1'].unique())\n",
    "print(\"Label types:\", train_data['PD-L1'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal features: {pdl1_clf._fxs[\"Ordinal\"]}')\n",
    "print(f'Categorical features: {pdl1_clf._fxs[\"Categorical\"]}')\n",
    "print(f'Numeric features: {pdl1_clf._fxs[\"Numeric\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_config(variable=\"train_transformed\")\n",
    "train['encoded_PDL1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_config(variable=\"test_transformed\")\n",
    "test['encoded_PDL1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models(sort='auc', n_select=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC for validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = create_model('lr')\n",
    "cv_results = pull()  # This gets the last displayed results\n",
    "print(cv_results)\n",
    "# fold_results = get_config('fold_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Evaluate the final model on the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import finalize_model, predict_model\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# 1) Finalize & predict\n",
    "final_model = finalize_model(best[0])\n",
    "preds_df    = predict_model(final_model, data=test_data)\n",
    "\n",
    "# PyCaret’s default DataFrame has:\n",
    "# - 'Label'           : the predicted class\n",
    "# - 'encoded_PDL1'    : the true class (if you passed it in test_data)\n",
    "# - Score_0,Score_1…  : class probabilities\n",
    "\n",
    "# 2) Extract true vs. pred\n",
    "y_true = preds_df['PD-L1']\n",
    "y_pred = preds_df['prediction_label']\n",
    "\n",
    "# 3) Compute metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=final_model.classes_,   # ensure class order\n",
    "    average=None                   # gives you per-class arrays\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Per‑class Precision/Recall/F1:\")\n",
    "for cls, p, r, f, s in zip(final_model.classes_, precision, recall, f1, support):\n",
    "    print(f\"  Class {cls}:  P={p:.3f}, R={r:.3f}, F1={f:.3f}  (n={s})\")\n",
    "\n",
    "# 4) (Optional) One‑line summary:\n",
    "print(\"\\nOverall classification report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\n",
    "    f\"PD‑L1 <1%\", \"PD‑L1 1–10%\", \"PD‑L1 >10%\"  # or however you’ve named them\n",
    "], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
